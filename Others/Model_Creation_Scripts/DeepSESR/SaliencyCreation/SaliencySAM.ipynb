{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "machine_shape": "hm",
      "gpuType": "V28"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "TPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "!pip install segment-anything\n",
        "!pip install opencv-python matplotlib"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "HuVMSYGvvrRJ",
        "outputId": "c8a698d7-30e7-47ab-b6ed-e2343fc3d1eb"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: segment-anything in /usr/local/lib/python3.10/dist-packages (1.0)\n",
            "Requirement already satisfied: opencv-python in /usr/local/lib/python3.10/dist-packages (4.10.0.84)\n",
            "Requirement already satisfied: matplotlib in /usr/local/lib/python3.10/dist-packages (3.7.1)\n",
            "Requirement already satisfied: numpy>=1.21.2 in /usr/local/lib/python3.10/dist-packages (from opencv-python) (1.26.4)\n",
            "Requirement already satisfied: contourpy>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib) (1.3.0)\n",
            "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.10/dist-packages (from matplotlib) (0.12.1)\n",
            "Requirement already satisfied: fonttools>=4.22.0 in /usr/local/lib/python3.10/dist-packages (from matplotlib) (4.54.1)\n",
            "Requirement already satisfied: kiwisolver>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib) (1.4.7)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.10/dist-packages (from matplotlib) (24.1)\n",
            "Requirement already satisfied: pillow>=6.2.0 in /usr/local/lib/python3.10/dist-packages (from matplotlib) (10.4.0)\n",
            "Requirement already satisfied: pyparsing>=2.3.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib) (3.1.4)\n",
            "Requirement already satisfied: python-dateutil>=2.7 in /usr/local/lib/python3.10/dist-packages (from matplotlib) (2.9.0.post0)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.10/dist-packages (from python-dateutil>=2.7->matplotlib) (1.16.0)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "nnsJN9ckvCeM"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "import torchvision\n",
        "import sys\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import cv2\n",
        "import json\n",
        "from IPython.display import display, clear_output\n",
        "import os\n",
        "from google.colab import drive\n",
        "from segment_anything import sam_model_registry, SamPredictor"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Mount Google Drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ohLuqy3DvckZ",
        "outputId": "07c8c94f-c514-4cbd-fdef-aadba0b65cfe"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"PyTorch version:\", torch.__version__)\n",
        "print(\"Torchvision version:\", torchvision.__version__)\n",
        "print(\"CUDA is available:\", torch.cuda.is_available())"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "T_4s_wJxv7q5",
        "outputId": "9819f830-5fe0-45dd-8443-9eccb4e78aa6"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "PyTorch version: 2.4.0+cpu\n",
            "Torchvision version: 0.19.0+cpu\n",
            "CUDA is available: False\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Download SAM model if not already present\n",
        "if not os.path.exists(\"sam_vit_h_4b8939.pth\"):\n",
        "    !wget https://dl.fbaipublicfiles.com/segment_anything/sam_vit_h_4b8939.pth"
      ],
      "metadata": {
        "id": "MllOuzUUwBEY"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def show_mask(mask, ax, random_color=False):\n",
        "    if random_color:\n",
        "        color = np.concatenate([np.random.random(3), np.array([0.6])], axis=0)\n",
        "    else:\n",
        "        color = np.array([30/255, 144/255, 255/255, 0.6])\n",
        "    h, w = mask.shape[-2:]\n",
        "    mask_image = mask.reshape(h, w, 1) * color.reshape(1, 1, -1)\n",
        "    ax.imshow(mask_image)\n",
        "\n",
        "def show_points(coords, labels, ax, marker_size=375):\n",
        "    pos_points = coords[labels==1]\n",
        "    neg_points = coords[labels==0]\n",
        "    ax.scatter(pos_points[:, 0], pos_points[:, 1], color='green', marker='*', s=marker_size, edgecolor='white', linewidth=1.25)\n",
        "    ax.scatter(neg_points[:, 0], neg_points[:, 1], color='red', marker='*', s=marker_size, edgecolor='white', linewidth=1.25)\n",
        "\n",
        "def show_box(box, ax):\n",
        "    x0, y0 = box[0], box[1]\n",
        "    w, h = box[2] - box[0], box[3] - box[1]\n",
        "    ax.add_patch(plt.Rectangle((x0, y0), w, h, edgecolor='green', facecolor=(0,0,0,0), lw=2))"
      ],
      "metadata": {
        "id": "Lkll_uvwv4hv"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def load_and_display_images(folder_path):\n",
        "    images = []\n",
        "    for filename in os.listdir(folder_path):\n",
        "        if filename.endswith((\".jpg\", \".jpeg\", \".png\")):\n",
        "            img_path = os.path.join(folder_path, filename)\n",
        "            img = cv2.imread(img_path)\n",
        "            img = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)\n",
        "            images.append((filename, img))\n",
        "            plt.figure(figsize=(10,10))\n",
        "            plt.imshow(img)\n",
        "            plt.title(filename)\n",
        "            plt.axis('on')\n",
        "            plt.show()\n",
        "    return images\n",
        "\n",
        "def choose_json_file(json_path):\n",
        "    print(f\"Checking for JSON file at: {json_path}\")\n",
        "    if os.path.exists(json_path):\n",
        "        print(f\"JSON file found at {json_path}.\")\n",
        "        use_existing = input(\"Use existing file? (yes/no): \").lower() == 'yes'\n",
        "        if use_existing:\n",
        "            with open(json_path, 'r') as f:\n",
        "                return json.load(f), True\n",
        "        else:\n",
        "            return {}, False\n",
        "    else:\n",
        "        print(f\"No existing JSON file found at {json_path}. A new file will be created.\")\n",
        "        return {}, False\n",
        "\n",
        "def create_saliency_map(mask, output_path):\n",
        "    saliency = (mask * 255).astype(np.uint8)\n",
        "    saliency = cv2.resize(saliency, (1920, 1080), interpolation=cv2.INTER_NEAREST)\n",
        "    cv2.imwrite(output_path, saliency)\n"
      ],
      "metadata": {
        "id": "0VDksv1p0__S"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def process_images(images, json_path, saliency_folder, use_existing_json, existing_data):\n",
        "    image_points = existing_data if use_existing_json else {}\n",
        "\n",
        "    sam_checkpoint = \"sam_vit_h_4b8939.pth\"\n",
        "    model_type = \"vit_h\"\n",
        "    device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
        "    sam = sam_model_registry[model_type](checkpoint=sam_checkpoint)\n",
        "    sam.to(device=device)\n",
        "    predictor = SamPredictor(sam)\n",
        "\n",
        "    for filename, image in images:\n",
        "        if filename in image_points and use_existing_json:\n",
        "            print(f\"Using existing points for {filename}\")\n",
        "            input_points = np.array(image_points[filename])\n",
        "\n",
        "            # Display image with existing points\n",
        "            plt.figure(figsize=(10,10))\n",
        "            plt.imshow(image)\n",
        "            show_points(input_points, np.ones(len(input_points)), plt.gca())\n",
        "            plt.title(f\"Existing points for {filename}\")\n",
        "            plt.axis('off')\n",
        "            plt.show()\n",
        "\n",
        "            # Generate mask using existing points\n",
        "            predictor.set_image(image)\n",
        "            masks, scores, logits = predictor.predict(\n",
        "                point_coords=input_points,\n",
        "                point_labels=np.ones(len(input_points)),\n",
        "                multimask_output=True,\n",
        "            )\n",
        "\n",
        "            # Display masks\n",
        "            for i, (mask, score) in enumerate(zip(masks, scores)):\n",
        "                plt.figure(figsize=(10,10))\n",
        "                plt.imshow(image)\n",
        "                show_mask(mask, plt.gca())\n",
        "                show_points(input_points, np.ones(len(input_points)), plt.gca())\n",
        "                plt.title(f\"Mask {i+1}, Score: {score:.3f}\", fontsize=18)\n",
        "                plt.axis('off')\n",
        "                plt.show()\n",
        "\n",
        "            # Ask user to choose the best mask or redo\n",
        "            choice = input(\"Enter the number of the best mask (or 'redo' to input new points): \")\n",
        "            if choice.lower() == 'redo':\n",
        "                use_existing_json = False\n",
        "            else:\n",
        "                best_mask_index = int(choice) - 1\n",
        "\n",
        "                # Create and save saliency map\n",
        "                saliency_filename = f\"{os.path.splitext(filename)[0]}_Saliency.jpeg\"\n",
        "                saliency_path = os.path.join(saliency_folder, saliency_filename)\n",
        "                create_saliency_map(masks[best_mask_index], saliency_path)\n",
        "                print(f\"Saliency map saved to {saliency_path}\")\n",
        "                continue\n",
        "\n",
        "        while True:\n",
        "            points_input = input(f\"Enter points for {filename} as x1,y1 x2,y2 ... (or 'skip' to skip this image): \")\n",
        "            if points_input.lower() == 'skip':\n",
        "                break\n",
        "\n",
        "            input_points = np.array([list(map(float, p.split(','))) for p in points_input.split()])\n",
        "            input_labels = np.ones(len(input_points))\n",
        "\n",
        "            predictor.set_image(image)\n",
        "            masks, scores, logits = predictor.predict(\n",
        "                point_coords=input_points,\n",
        "                point_labels=input_labels,\n",
        "                multimask_output=True,\n",
        "            )\n",
        "\n",
        "            for i, (mask, score) in enumerate(zip(masks, scores)):\n",
        "                plt.figure(figsize=(10,10))\n",
        "                plt.imshow(image)\n",
        "                show_mask(mask, plt.gca())\n",
        "                show_points(input_points, input_labels, plt.gca())\n",
        "                plt.title(f\"Mask {i+1}, Score: {score:.3f}\", fontsize=18)\n",
        "                plt.axis('off')\n",
        "                plt.show()\n",
        "\n",
        "            choice = input(\"Enter the number of the best mask (or 'redo' to input new points): \")\n",
        "            if choice.lower() == 'redo':\n",
        "                continue\n",
        "\n",
        "            best_mask_index = int(choice) - 1\n",
        "            image_points[filename] = input_points.tolist()\n",
        "\n",
        "            # Create and save saliency map\n",
        "            saliency_filename = f\"{os.path.splitext(filename)[0]}_Saliency.jpeg\"\n",
        "            saliency_path = os.path.join(saliency_folder, saliency_filename)\n",
        "            create_saliency_map(masks[best_mask_index], saliency_path)\n",
        "            print(f\"Saliency map saved to {saliency_path}\")\n",
        "\n",
        "            break\n",
        "\n",
        "        # Save to JSON after each image\n",
        "        with open(json_path, 'w') as f:\n",
        "            json.dump(image_points, f, indent=2)\n",
        "        print(f\"Points saved to {json_path}\")\n",
        "\n",
        "    return image_points"
      ],
      "metadata": {
        "id": "Cdv7TJXDwK-m"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def process_all_batches(base_folder):\n",
        "    batch_folders = ['Batch_Seven']\n",
        "\n",
        "\n",
        "    for batch in batch_folders:\n",
        "        folder_path = os.path.join(base_folder, batch)\n",
        "\n",
        "        # Special case for Batch One\n",
        "        if batch == 'Batch_One':\n",
        "            json_filename = 'image_points.json'\n",
        "        else:\n",
        "            json_filename = f'image_points_{batch.lower()}.json'\n",
        "\n",
        "        json_path = os.path.join(folder_path, json_filename)\n",
        "        saliency_folder = os.path.join(base_folder, 'Saliency', batch)\n",
        "\n",
        "        print(f\"\\nProcessing {batch}\")\n",
        "        print(f\"Folder path: {folder_path}\")\n",
        "        print(f\"JSON path: {json_path}\")\n",
        "        print(f\"Saliency folder: {saliency_folder}\")\n",
        "\n",
        "        if not os.path.exists(folder_path):\n",
        "            print(f\"Warning: Folder {folder_path} does not exist. Skipping this batch.\")\n",
        "            continue\n",
        "\n",
        "        os.makedirs(saliency_folder, exist_ok=True)\n",
        "\n",
        "        images = load_and_display_images(folder_path)\n",
        "        print(f\"Total images loaded: {len(images)}\")\n",
        "\n",
        "        existing_data, use_existing_json = choose_json_file(json_path)\n",
        "\n",
        "        final_image_points = process_images(images, json_path, saliency_folder, use_existing_json, existing_data)\n",
        "        print(f\"Final image points for {batch}:\")\n",
        "        print(json.dumps(final_image_points, indent=2))\n"
      ],
      "metadata": {
        "id": "CXUYHC7EwNIQ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Main execution\n",
        "base_folder = '/content/drive/MyDrive/Data/images/'\n",
        "print(f\"Base folder: {base_folder}\")\n",
        "process_all_batches(base_folder)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "t9lDpjiqwSzB",
        "outputId": "6970300a-9ec4-48d6-9ede-74970b1f356e"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}